{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline begins by importing the required packages\n",
    "It then loads the excel file and splits it into X's (all columns apart from the last) and Y (the last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Plot F -TEST and other test\n",
    "\n",
    "# Add optimisation graphes at bottom\n",
    "\n",
    "# ELI 5\n",
    "\n",
    "# plot all train and test sets after each iteration \n",
    "\n",
    "# do all scaled and unscaled!!!!\n",
    "\n",
    "# Automate removing of columns and feature engineering then do it again\n",
    "\n",
    "# Save all model outputs as variables for a table at the end\n",
    "\n",
    "# standard scale the whole dataframe, keep as a seperate variable, use for graphes at end of explore set\n",
    "\n",
    "# F tests and mutual dependency from sikitlearn website\n",
    "\n",
    "# At the end plot a table of all the best models and all the coefficients of each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Here the ML models are imported - in order\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the excel file\n",
    "# The file is used here and in a latter part of the script, but it is needed for \n",
    "filename = \"xxxxx\"\n",
    "dataset = pd.read_excel(filename)\n",
    "\n",
    "# Creates the facotrs as X and the responses as Y\n",
    "# Y is assumed to be the last column of the excell file\n",
    "# The .values here is important as it gets a numpy array and not a pandas dataframe\n",
    "x = dataset.iloc[:,:-1].values      # Sets X - All apart from last column\n",
    "y = dataset.iloc[:,-1:].values      # Sets Y - Only the last column\n",
    "\n",
    "# QC testing, prints x, prints y and prints the length of x\n",
    "# It is called below but knocked off for neatness\n",
    "def qcPrinter(X,Y):\n",
    "    print(\"QC Function for X's and Y's\")\n",
    "    print(X)\n",
    "    print(Y)\n",
    "    print(len(X))\n",
    "    print(len(Y))\n",
    "\n",
    "# Below the QC Function is knocked off, knock it on for troubleshooting\n",
    "# qcPrinter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we print the cols in different ways\n",
    "# pull in later for labelling of axes\n",
    "\n",
    "# iterating the columns \n",
    "for col in dataset.iloc[:,:-1].columns: \n",
    "    print(col)\n",
    "    \n",
    "axe= list(dataset.iloc[:,:-1].columns.values.tolist()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data is split into training and test sets, this happens 3 times \n",
    "1 unscaled, \n",
    "2 scaled via standard scaler\n",
    "3 normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the training and test dataset\n",
    "\n",
    "# Makes a 80 / 20 split, svaes in random state 4 for tracability\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=4)\n",
    "#qcPrinter(x_train,y_train)\n",
    "#qcPrinter(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling using Standard Scaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "x_scaled = sc_x.fit_transform(x)\n",
    "y_scaled = sc_y.fit_transform(y)\n",
    "\n",
    "x_train_sc, x_test_sc, y_train_sc, y_test_sc = train_test_split(x_scaled,y_scaled,test_size=0.2,random_state=4)\n",
    "\n",
    "#qcPrinter(x_train_sc,y_train_sc)\n",
    "#qcPrinter(x_test_sc,y_test_sc)\n",
    "\n",
    "#TODO\n",
    "# df['colname'] = df['colname'].astype(float) This will get rid of the float error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the whole dataset for graphing purposes\n",
    "dataset_scale_function = StandardScaler()\n",
    "dataset_scaled = dataset_scale_function.fit_transform(dataset)\n",
    "# Below is a QC test to see the scaled dataset\n",
    "print(dataset_scaled)\n",
    "print(dataset_scaled[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data attributes\n",
    "# This takes the first dataframe as an input\n",
    "nx_train = preprocessing.normalize(x_train)\n",
    "nx_test = preprocessing.normalize(x_test)\n",
    "ny_train = preprocessing.normalize(y_train)\n",
    "ny_test = preprocessing.normalize(y_test)\n",
    "\n",
    "# qcPrinter(nx_train,ny_train)\n",
    "# qcPrinter(nx_test,ny_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here the operator is given the option to chagne all the x and y to scaled or normalised if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setter = 0\n",
    "if setter == 1:\n",
    "    x_train = x_train_sc\n",
    "    x_test = x_test_sc\n",
    "    y_train = y_train_sc\n",
    "    y_test = y_test_sc    \n",
    "elif setter ==2:\n",
    "    x_train = nx_train\n",
    "    x_test = nx_test\n",
    "    y_train = ny_train\n",
    "    y_test = ny_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here the data is explored\n",
    "\n",
    "1 - Correlation Matrix\n",
    "2 - PCA analyss\n",
    "3 - Make functions to do some 4 factor maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives an idea of how balanced the dataset is\n",
    "\n",
    "dataset.hist(bins=50,figsize=(20,15))                           # Prints histograms for all the end data\n",
    "#data_spread_1=plt.savefig(\"data_spread_1.png\")                 # Saves the graph as output_one\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix, rough idea of correlations\n",
    "\n",
    "corrmat = dataset.corr()\n",
    "top_corr_features=corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plt heatmap\n",
    "g=sns.heatmap(dataset[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the head of the dataframe to get the names for below\n",
    "\n",
    "print(dataset.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we need to plot the main players, entered from the above headings, \n",
    "\n",
    "# Below alters the size of the graph by the width and height variables\n",
    "width = 25 \n",
    "height =20\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "# These need to be manually entered depending on what the operator wants to view\n",
    "At1 = \"A\"\n",
    "At2 = \"B\"\n",
    "At3 = \"C\"\n",
    "At4 = \"D\"\n",
    "At5 = \"E\"\n",
    "attributes =[At1,At2,At3,At4,At5]\n",
    "\n",
    "# Here the s =, makes the size of the dots\n",
    "scatter_one = scatter_matrix(dataset[attributes],s=170)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we begin fitting linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Linear - OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we fit a very simple linear regression (OLS)\n",
    "\n",
    "# Set the model to the variable\n",
    "regressor = LinearRegression()\n",
    "# Fits it to an unscaled dataset\n",
    "regressor.fit(x_train,y_train)\n",
    "results_QC = str(regressor.fit(x_train,y_train))\n",
    "# predict \n",
    "y_pred = regressor.predict(x_test)   \n",
    "# Predicts the x test group based on the fitting of the regressor to the x train and the y train\n",
    "\n",
    "# Here we get the training and test score for the linear regressor model\n",
    "# First we assign them to variables\n",
    "Lin_unscaled_train = (regressor.score(x_train,y_train))\n",
    "Lin_unscaled_test = (regressor.score(x_test,y_test))\n",
    "# Then we print out the outputs\n",
    "print(\"Training set score Linear Regressor: {:.2f}\".format(regressor.score(x_train,y_train)))\n",
    "print(\"Test set score Linear Regressor: {:.2f}\".format(regressor.score(x_test,y_test)))\n",
    "\n",
    "# Prints both actual and predicted as lists - QC Tests so conocked off\n",
    "# print(y_pred)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "#Here the figure size is reset\n",
    "width = 10 \n",
    "height =10\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "# Plot a simple graph to see how well it fits\n",
    "plt.scatter(y_test, y_pred, color ='blue')\n",
    "plt.title('Linear Regression - Actual by Predicted')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "print(\"Results obtained via\",results_QC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we fit a linear regression model again, printing the train and test scores but also looking \n",
    "# at the coefficients of the models\n",
    "\n",
    "lr = LinearRegression().fit(x_train,y_train)\n",
    "lin_coef = lr.coef_\n",
    "# Here we print the coefficients and the intercepts\n",
    "print(\"lr.coef_:\", lr.coef_)\n",
    "print(\"lr.intercept\", lr.intercept_)\n",
    "\n",
    "print(\"Training set score: {:.2f}\".format(lr.score(x_train,y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model - Ridge Regression\n",
    "\n",
    "\n",
    "Reguralized Linear Regression -It will try and minimize feature impacts\n",
    "\n",
    "####L2 Regularization technique - Objective = RSS + α * (sum of square of coefficients)\n",
    "\n",
    "\n",
    "We tune alpha from the most complex to least complex model, print a graph of the tranining and test sets\n",
    "\n",
    "Then print the actuall by predicted for the best model¶\n",
    "\n",
    "####It shrinks the parameters, therefore it is mostly used to prevent multicollinearity.\n",
    "\n",
    "####It reduces the model complexity by coefficient shrinkage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Some Feature Engineering for at least 3 different features\n",
    "# here we fit a ridge regression\n",
    "\n",
    "ridge = Ridge().fit(x_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train,y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test,y_test)))\n",
    "\n",
    "# Here we do a ridge with an alpha of 10\n",
    "ridge10 = Ridge(alpha=10).fit(x_train, y_train)\n",
    "print(\"Training set ridge 10 score: {:.2f}\".format(ridge10.score(x_train,y_train)))\n",
    "print(\"Test set ridge 10 score: {:.2f}\".format(ridge10.score(x_test,y_test)))\n",
    "\n",
    "training_accuracy_ridge = []\n",
    "test_acc_ridge = []\n",
    "\n",
    "#neighbors_settings = range(0.01)\n",
    "# build the models\n",
    "ridge_a = Ridge(alpha=0.0000001)\n",
    "ridge_a.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_a.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_a.score(x_test,y_test))\n",
    "\n",
    "ridge_b = Ridge(alpha=0.000001)\n",
    "ridge_b.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_b.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_b.score(x_test,y_test))\n",
    "\n",
    "ridge_c = Ridge(alpha=0.00001)\n",
    "ridge_c.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_c.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_c.score(x_test,y_test))\n",
    "\n",
    "ridge_d = Ridge(alpha=0.0001)\n",
    "ridge_d.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_d.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_d.score(x_test,y_test))\n",
    "\n",
    "ridge_e = Ridge(alpha=0.001)\n",
    "ridge_e.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_e.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_e.score(x_test,y_test))\n",
    "\n",
    "ridge_f = Ridge(alpha=0.01)\n",
    "ridge_f.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_f.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_f.score(x_test,y_test))\n",
    "\n",
    "ridge_g = Ridge(alpha=0.1)\n",
    "ridge_g.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_g.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_g.score(x_test,y_test))\n",
    "\n",
    "ridge_h = Ridge(alpha=1.0)\n",
    "ridge_h.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_h.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_h.score(x_test,y_test))\n",
    "\n",
    "ridge_i = Ridge(alpha=10.0)\n",
    "ridge_i.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_i.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_i.score(x_test,y_test))\n",
    "\n",
    "ridge_j = Ridge(alpha=100.0)\n",
    "ridge_j.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_j.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_j.score(x_test,y_test))\n",
    "\n",
    "ridge_k = Ridge(alpha=1000.0)\n",
    "ridge_k.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_k.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_k.score(x_test,y_test))\n",
    "\n",
    "ridge_l = Ridge(alpha=10000.0)\n",
    "ridge_l.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_l.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_l.score(x_test,y_test))\n",
    "\n",
    "\n",
    "alpha_settings = (\"1e-7\",\"1e-6\",\"1e-5\",\"1e-4\",\"1e-3\",\"1e-2\",\"1e-1\",\"1\",\"10\",\"100\",\"1000\",\"100000\")\n",
    "plt.plot(alpha_settings,training_accuracy_ridge,label = \"training accuracy\")\n",
    "plt.plot(alpha_settings,test_acc_ridge,label=\"test accuracy\")\n",
    "plt.title('Training vs Test Graph - Ridge Regression - Unscaled')\n",
    "plt.ylabel(\"Accuracy (R^2)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.legend()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below copies the same format as above however it uses scaled x's and y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Some Feature Engineering for at least 3 different features\n",
    "# here we fir a ridge regression\n",
    "\n",
    "ridge = Ridge().fit(x_train_sc, y_train_sc)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train_sc,y_train_sc)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test_sc,y_test_sc)))\n",
    "\n",
    "# Here we do a ridge with an alpha of 10\n",
    "ridge10 = Ridge(alpha=10).fit(x_train_sc, y_train_sc)\n",
    "print(\"Training set ridge 10 score: {:.2f}\".format(ridge10.score(x_train_sc,y_train_sc)))\n",
    "print(\"Test set ridge 10 score: {:.2f}\".format(ridge10.score(x_test_sc,y_test_sc)))\n",
    "\n",
    "training_accuracy_ridge = []\n",
    "test_acc_ridge = []\n",
    "\n",
    "#neighbors_settings = range(0.01)\n",
    "# build the models\n",
    "ridge_a = Ridge(alpha=0.0000001)\n",
    "ridge_a.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_a.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_a.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_b = Ridge(alpha=0.000001)\n",
    "ridge_b.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_b.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_b.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_c = Ridge(alpha=0.00001)\n",
    "ridge_c.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_c.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_c.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_d = Ridge(alpha=0.0001)\n",
    "ridge_d.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_d.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_d.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_e = Ridge(alpha=0.001)\n",
    "ridge_e.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_e.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_e.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_f = Ridge(alpha=0.01)\n",
    "ridge_f.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_f.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_f.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_g = Ridge(alpha=0.1)\n",
    "ridge_g.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_g.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_g.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_h = Ridge(alpha=1.0)\n",
    "ridge_h.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_h.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_h.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_i = Ridge(alpha=10.0)\n",
    "ridge_i.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_i.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_i.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_j = Ridge(alpha=100.0)\n",
    "ridge_j.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_j.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_j.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_k = Ridge(alpha=1000.0)\n",
    "ridge_k.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_k.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_k.score(x_test_sc,y_test_sc))\n",
    "\n",
    "ridge_l = Ridge(alpha=10000.0)\n",
    "ridge_l.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_l.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_l.score(x_test_sc,y_test_sc))\n",
    "\n",
    "\n",
    "alpha_settings = (\"1e-7\",\"1e-6\",\"1e-5\",\"1e-4\",\"1e-3\",\"1e-2\",\"1e-1\",\"1\",\"10\",\"100\",\"1000\",\"100000\")\n",
    "plt.plot(alpha_settings,training_accuracy_ridge,label = \"training accuracy\")\n",
    "plt.plot(alpha_settings,test_acc_ridge,label=\"test accuracy\")\n",
    "plt.title('Training vs Test Graph - Ridge Regression - Scaled')\n",
    "plt.ylabel(\"Accuracy (R^2)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.legend()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we fit the best ridge regressor\n",
    "\n",
    "# Set the model to the variable\n",
    "chosen_ridge = Ridge(alpha=0.01)\n",
    "# Fits it to an unscaled dataset\n",
    "chosen_ridge.fit(x_train,y_train)\n",
    "results_QC = str(chosen_ridge.fit(x_train,y_train))\n",
    "# predict \n",
    "y_pred = chosen_ridge.predict(x_test)   \n",
    "# Predicts the x test group based on the fitting of the regressor to the x train and the y train\n",
    "\n",
    "# Here we get the training and test score for the linear regressor model\n",
    "# First we assign them to variables\n",
    "chosen_ridge_train = (chosen_ridge.score(x_train,y_train))\n",
    "chosen_ridge_test = (chosen_ridge.score(x_test,y_test))\n",
    "# Then we print out the outputs\n",
    "print(\"Training set score chosen ridge: {:.2f}\".format(chosen_ridge.score(x_train,y_train)))\n",
    "print(\"Test set score chosen rdge: {:.2f}\".format(chosen_ridge.score(x_test,y_test)))\n",
    "\n",
    "# Prints both actual and predicted as lists - QC Tests so conocked off\n",
    "# print(y_pred)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "#Here the figure size is reset\n",
    "width = 10 \n",
    "height =10\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "# Plot a simple graph to see how well it fits\n",
    "plt.scatter(y_test, y_pred, color ='blue')\n",
    "plt.title('Chosen_ridge - Actual by Predicted')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "print(\"Results obtained via\",results_QC)\n",
    "\n",
    "#Get the coefficients of the model\n",
    "print(\"coef_:\", chosen_ridge.coef_)\n",
    "# Variable below is used in a graph\n",
    "rid_coef= chosen_ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Model - Lassoo Regression\n",
    "\n",
    "##LASSO (Least Absolute Shrinkage Selector Operator), is quite similar to ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###We can see that as we increased the value of alpha, coefficients were approaching towards zero,\n",
    "\n",
    "###but if you see in case of lasso, even at smaller alpha’s, our coefficients are reducing to absolute zeroes. \n",
    "\n",
    "###Therefore, lasso selects the only some feature while reduces the coefficients of others to zero. This property is \n",
    "\n",
    "###known as feature selection and which is absent in case of ridge.\n",
    "\n",
    "###Mathematics behind lasso regression is quiet similar to that of ridge only difference being instead of adding \n",
    "\n",
    "###squares of theta, we will add absolute value of Θ.\n",
    "\n",
    "####It uses L1 regularization technique (will be discussed later in this article)\n",
    "\n",
    "####It is generally used when we have more number of features, because it automatically does feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a lassoo\n",
    "\n",
    "\n",
    "# Fit a standard lasso with no variation on alpha or iterations\n",
    "lasso = Lasso().fit(x_train,y_train)\n",
    "# prints the train and test scores\n",
    "print(\"Standard untrained Lasso model\")\n",
    "print(\"Training set score {:.2f}\".format(lasso.score(x_train,y_train)))\n",
    "print(\"Tet set score {:.2f}\".format(lasso.score(x_test,y_test)))\n",
    "print(\"number of features used by standard untrined Lasso:\", np.sum(lasso.coef_!=0))\n",
    "print(\"Here we go next\")\n",
    "# In the same manner as previous, create empty arrays to append the lasso regression onto\n",
    "training_accuracy_l = []\n",
    "test_acc_l = []\n",
    "\n",
    "# build the models\n",
    "las_reg_1 = Lasso(alpha=0.0001)\n",
    "las_reg_1.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_1.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_1.score(x_test,y_test))\n",
    "\n",
    "las_reg_2 = Lasso(alpha=0.001)\n",
    "las_reg_2.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_2.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_2.score(x_test,y_test))\n",
    "\n",
    "\n",
    "las_reg_3 = Lasso(alpha=0.01)\n",
    "las_reg_3.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_3.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_3.score(x_test,y_test))\n",
    "\n",
    "las_reg_4 = Lasso(alpha=0.1)\n",
    "las_reg_4.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_4.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_4.score(x_test,y_test))\n",
    "\n",
    "las_reg_5 = Lasso(alpha=1)\n",
    "las_reg_5.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_5.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_5.score(x_test,y_test))\n",
    "\n",
    "las_reg_6 = Lasso(alpha=10)\n",
    "las_reg_6.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_6.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_6.score(x_test,y_test))\n",
    "\n",
    "las_reg_7 = Lasso(alpha=100)\n",
    "las_reg_7.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_7.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_7.score(x_test,y_test))\n",
    "\n",
    "las_reg_8 = Lasso(alpha=1000)\n",
    "las_reg_8.fit(x_train,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_8.score(x_train,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_8.score(x_test,y_test))\n",
    "\n",
    "\n",
    "alpha_settings = (\"1e-4\",\"1e-3\",\"1e-2\",\"1e-1\",\"1\",\"10\",\"100\",\"1000\")\n",
    "plt.plot(alpha_settings,training_accuracy_l,label = \"training accuracy\")\n",
    "plt.plot(alpha_settings,test_acc_l,label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy (R^2)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do the same as above but with a scaled x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a lassoo\n",
    "\n",
    "# Fit a standard lasso with no variation on alpha or iterations\n",
    "lasso = Lasso().fit(x_train_sc,y_train_sc)\n",
    "# prints the train and test scores\n",
    "print(\"Standard untrained Lasso model\")\n",
    "print(\"Training set score {:.2f}\".format(lasso.score(x_train_sc,y_train_sc)))\n",
    "print(\"Tet set score {:.2f}\".format(lasso.score(x_test_sc,y_test_sc)))\n",
    "print(\"number of features used by standard untrined Lasso:\", np.sum(lasso.coef_!=0))\n",
    "print(\"Here we go next\")\n",
    "# In the same manner as previous, create empty arrays to append the lasso regression onto\n",
    "training_accuracy_l = []\n",
    "test_acc_l = []\n",
    "\n",
    "# build the models\n",
    "las_reg_1 = Lasso(alpha=0.0001)\n",
    "las_reg_1.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_1.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_1.score(x_test_sc,y_test_sc))\n",
    "\n",
    "las_reg_2 = Lasso(alpha=0.001)\n",
    "las_reg_2.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_2.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_2.score(x_test_sc,y_test_sc))\n",
    "\n",
    "\n",
    "las_reg_3 = Lasso(alpha=0.01)\n",
    "las_reg_3.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_3.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_3.score(x_test_sc,y_test_sc))\n",
    "\n",
    "las_reg_4 = Lasso(alpha=0.1)\n",
    "las_reg_4.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_4.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_4.score(x_test_sc,y_test_sc))\n",
    "\n",
    "las_reg_5 = Lasso(alpha=1)\n",
    "las_reg_5.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_5.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_5.score(x_test_sc,y_test_sc))\n",
    "\n",
    "las_reg_6 = Lasso(alpha=10)\n",
    "las_reg_6.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_6.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_6.score(x_test_sc,y_test_sc))\n",
    "\n",
    "las_reg_7 = Lasso(alpha=100)\n",
    "las_reg_7.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_7.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_7.score(x_test_sc,y_test_sc))\n",
    "\n",
    "las_reg_8 = Lasso(alpha=1000)\n",
    "las_reg_8.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_8.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_8.score(x_test_sc,y_test_sc))\n",
    "\n",
    "\n",
    "alpha_settings = (\"1e-4\",\"1e-3\",\"1e-2\",\"1e-1\",\"1\",\"10\",\"100\",\"1000\")\n",
    "plt.plot(alpha_settings,training_accuracy_l,label = \"training accuracy\")\n",
    "plt.plot(alpha_settings,test_acc_l,label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy (R^2)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we fit the best Lasso\n",
    "\n",
    "\n",
    "# Set the model to the variable\n",
    "chosen_Lasso = Lasso(alpha=0.01)\n",
    "# Fits it to an unscaled dataset\n",
    "chosen_Lasso.fit(x_train,y_train)\n",
    "results_QC = str(chosen_Lasso.fit(x_train,y_train))\n",
    "# predict \n",
    "y_pred = chosen_Lasso.predict(x_test)   \n",
    "# Predicts the x test group based on the fitting of the regressor to the x train and the y train\n",
    "\n",
    "# Here we get the training and test score for the linear regressor model\n",
    "# First we assign them to variables\n",
    "chosen_Lasso_train = (chosen_Lasso.score(x_train,y_train))\n",
    "chosen_Lasso_test = (chosen_Lasso.score(x_test,y_test))\n",
    "# Then we print out the outputs\n",
    "print(\"Training set score chosen ridge: {:.2f}\".format(chosen_Lasso.score(x_train,y_train)))\n",
    "print(\"Test set score chosen rdge: {:.2f}\".format(chosen_Lasso.score(x_test,y_test)))\n",
    "\n",
    "# Prints both actual and predicted as lists - QC Tests so conocked off\n",
    "# print(y_pred)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "#Here the figure size is reset\n",
    "width = 10 \n",
    "height =10\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "# Plot a simple graph to see how well it fits\n",
    "plt.scatter(y_test, y_pred, color ='blue')\n",
    "plt.title('Chosen_Lasso - Actual by Predicted')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "print(\"Results obtained via\",results_QC)\n",
    "\n",
    "#Get the coefficients of the model\n",
    "print(\"coef_:\", chosen_Lasso.coef_)\n",
    "# Variable below is used in a graph\n",
    "Lasso_coef= chosen_Lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Model - KNN Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is made in a more efficient fasihion than the other models.\n",
    "# We can update the other models if needed - or possibly put it all in a funciton\n",
    "\n",
    "# KNN Does not give a coefficent importance due to how it is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_accuracy = []\n",
    "test_acc = []\n",
    "\n",
    "# Here we set the range to between 1 and 15\n",
    "neighbors_settings = range(1,15)\n",
    "\n",
    "# this iterates over all the numbers in the range and appends the training and test scres to each one\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the models\n",
    "    knn_reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    knn_reg.fit(x_train,y_train)\n",
    "    # record the accuracy\n",
    "    training_accuracy.append(knn_reg.score(x_train,y_train))\n",
    "    # record generalization accuracy\n",
    "    test_acc.append(knn_reg.score(x_test,y_test))\n",
    "\n",
    "\n",
    "# Makes a plot of the training vs test accuracy\n",
    "plt.plot(neighbors_settings,training_accuracy,label = \"training accuracy\")\n",
    "plt.plot(neighbors_settings,test_acc,label=\"test accuracy\")\n",
    "plt.title(\"K Neighbors Regressor\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "\n",
    "# If model is good we cna predict, if not we need to moove on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best actuall by predicted below\n",
    "n_neighbors = 6\n",
    "chosen_knn_reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "chosen_knn_reg.fit(x_train,y_train)\n",
    "y_pred_knn = chosen_knn_reg.predict(x_test)\n",
    "#plt.scatter(X_test, y_test, color = 'red')   # Here the train values is set to the test vales\n",
    "plt.scatter(y_test_sc, y_pred_knn, color ='blue')\n",
    "plt.title('Best K Neighbors Regressor Actual vs Predicted, n_neighbors = ')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "# QC Dataset prints\n",
    "#print(y_test_sc)\n",
    "#print(y_pred_svr)\n",
    "# Prints the Training and test accuracy for the selected KNN sets\n",
    "print(\"Training: {:.2f}\".format(chosen_knn_reg.score(x_train,y_train)))\n",
    "print(\"Test: {:.2f}\".format(chosen_knn_reg.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Model Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This uses combined L1 and L2 Reguralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can train alpha=1.0, l1_ratio=0.5\n",
    "# enet = ElasticNet(alpha=alpha, l1_ratio=0.7)\n",
    "# l1_ratiofloat, optional\n",
    "# Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). l1_ratio=1 corresponds to the Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The E net needs training from both l1 and alpha reg\n",
    "# Here the inputs are scaled as is most appropriate for this type of model\n",
    "\n",
    "# The L1 is the ratio for the L1 in every model, it will be scaled appropriatley\n",
    "theL1 = 0.8\n",
    "# This method is trained different, it is trained all through alpha, with l1_ratio set - we are ment to re run this scaling \n",
    "# the l1 ratio over and over.\n",
    "\n",
    "# Fit a standard ELlastic Net with no variation on alpha or 1l Reguralization\n",
    "enet = ElasticNet().fit(x_train_sc,y_train_sc)\n",
    "# prints the train and test scores\n",
    "print(\"Standard untrained ElasticNet model\")\n",
    "print(\"Training set score {:.2f}\".format(enet.score(x_train_sc,y_train_sc)))\n",
    "print(\"Tet set score {:.2f}\".format(enet.score(x_test_sc,y_test_sc)))\n",
    "print(\"number of features used by standard untrined Elastic Net:\", np.sum(enet.coef_!=0))\n",
    "print(\"Here we go next\")\n",
    "# In the same manner as previous, create empty arrays to append the lasso regression onto\n",
    "training_accuracy_enet = []\n",
    "test_acc_enet = []\n",
    "\n",
    "# build the models\n",
    "enet_reg_1 = ElasticNet(alpha=0.0001,l1_ratio =theL1)\n",
    "enet_reg_1.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet.append(enet_reg_1.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet.append(enet_reg_1.score(x_test_sc,y_test_sc))\n",
    "\n",
    "enet_reg_2 = ElasticNet(alpha=0.001,l1_ratio =theL1)\n",
    "enet_reg_2.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet.append(enet_reg_2.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet.append(enet_reg_2.score(x_test_sc,y_test_sc))\n",
    "\n",
    "enet_reg_3 = ElasticNet(alpha=0.01,l1_ratio =theL1)\n",
    "enet_reg_3.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet.append(enet_reg_3.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet.append(enet_reg_3.score(x_test_sc,y_test_sc))\n",
    "\n",
    "enet_reg_4 = ElasticNet(alpha=0.1,l1_ratio =theL1)\n",
    "enet_reg_4.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet.append(enet_reg_4.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet.append(enet_reg_4.score(x_test_sc,y_test_sc))\n",
    "\n",
    "enet_reg_5 = ElasticNet(alpha=1,l1_ratio =theL1)\n",
    "enet_reg_5.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet.append(enet_reg_5.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet.append(enet_reg_5.score(x_test_sc,y_test_sc))\n",
    "\n",
    "enet_reg_6 = ElasticNet(alpha=10,l1_ratio =theL1)\n",
    "enet_reg_6.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet.append(enet_reg_6.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet.append(enet_reg_6.score(x_test_sc,y_test_sc))\n",
    "\n",
    "enet_reg_7 = ElasticNet(alpha=100,l1_ratio =theL1)\n",
    "enet_reg_7.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet.append(enet_reg_7.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet.append(enet_reg_7.score(x_test_sc,y_test_sc))\n",
    "\n",
    "enet_reg_8 = ElasticNet(alpha=1000,l1_ratio =theL1)\n",
    "enet_reg_8.fit(x_train_sc,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet.append(enet_reg_8.score(x_train_sc,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet.append(enet_reg_8.score(x_test_sc,y_test_sc))\n",
    "\n",
    "\n",
    "alpha_settings = (\"1e-4\",\"1e-3\",\"1e-2\",\"1e-1\",\"1\",\"10\",\"100\",\"1000\")\n",
    "plt.plot(alpha_settings,training_accuracy_enet,label = \"training accuracy\")\n",
    "plt.plot(alpha_settings,test_acc_enet,label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy (R^2)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best actuall by predicted below\n",
    "# Here are the best parameters as a variable\n",
    "alpha = 10\n",
    "l1_ratio = 0.8\n",
    "\n",
    "chosen_enet = ElasticNet(alpha = alpha,l1_ratio =l1_ratio)\n",
    "chosen_enet.fit(x_train,y_train)\n",
    "y_pred_enet = chosen_enet.predict(x_test)\n",
    "#plt.scatter(X_test, y_test, color = 'red')   # Here the train values is set to the test vales\n",
    "plt.scatter(y_test_sc, y_pred_enet, color ='blue')\n",
    "plt.title('Best Elastic Net Regressor Actual vs Predicted, alpha =, l1 = ')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "# QC Dataset prints\n",
    "#print(y_test_sc)\n",
    "#print(y_pred_svr)\n",
    "# Prints the Training and test accuracy for the model\n",
    "print(\"Training: {:.2f}\".format(chosen_enet.score(x_train,y_train)))\n",
    "print(\"Test: {:.2f}\".format(chosen_enet.score(x_test,y_test)))\n",
    "\n",
    "#Get the coefficients of the model\n",
    "print(\"coef_:\", chosen_enet.coef_)\n",
    "# Variable below is used in a graph\n",
    "enet_coef= chosen_enet.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prints the best coefficients from the model above \n",
    "####issues with svcaling though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we fit the coefficient graph for all the best models\n",
    "\n",
    "# Need to alter the x axis names\n",
    "x_ax = axe\n",
    "\n",
    "#(\"x1\",\"x2\",\"x3\",\"x4\",\"x5\",\"x6\",\"x7\",\"x8\")\n",
    "\n",
    "\n",
    "lin_coef=np.array(lin_coef)\n",
    "lin_coef=lin_coef.flatten()\n",
    "\n",
    "rid_coef=np.array(rid_coef)\n",
    "rid_coef=rid_coef.flatten()\n",
    "\n",
    "Lasso_coef = np.array(Lasso_coef)\n",
    "Lasso_coef = Lasso_coef.flatten()\n",
    "\n",
    "# There is no coef call for a KNN model\n",
    "\n",
    "enet_coef = np.array(enet_coef)\n",
    "enet_coef = enet_coef.flatten()\n",
    "\n",
    "#lin_coef = list(lin_coef)\n",
    "plt.plot(x_ax,lin_coef,label = \"Linear Coef\")\n",
    "plt.plot(x_ax,rid_coef,label=\"Ridge Coef\")\n",
    "plt.plot(x_ax,Lasso_coef,label=\"Lasso Coef\")\n",
    "plt.plot(x_ax,enet_coef,label=\"Elastic Net Coef\")\n",
    "plt.ylabel(\"Coefficient Power\")\n",
    "plt.xlabel(\"Factor\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to print all the train and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this point we have 5 linear models, trained and optimised for all inputs in the system. We have the coefficients and the exporatory data for each x independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we import polynomial features into the model to asses multi factorial interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True, order='C')[source]¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports polynominal features to the power of 2, so x1, x1*x1, x2, x2*x2, x1*x2 etc\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "# Now we fit the poly features to the train and test sets, on the x axis only\n",
    "x_train_pol=poly.fit_transform(x_train)\n",
    "x_test_pol=poly.fit_transform(x_test)\n",
    "x_train_sc_poly = poly.fit_transform(x_train_sc)\n",
    "x_test_sc_poly = poly.fit_transform(x_test_sc)\n",
    "nx_train_poly = poly.fit_transform(nx_train)\n",
    "nx_test_poly = poly.fit_transform(nx_test)\n",
    "\n",
    "# here we print the properties of each feature for QC purposes \n",
    "poly_feats=poly.fit_transform(dataset.iloc[:,:-1])\n",
    "print(poly_feats)\n",
    "print(len(poly_feats))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we get the polynomial feature column headings\n",
    "refit = PolynomialFeatures(degree=2).fit(dataset.iloc[:,:-1])\n",
    "\n",
    "feat_name_poly = refit.get_feature_names(dataset.columns)\n",
    "print(len(feat_name_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have the poly features we can re-fit the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear with Poly Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we fit a very simple linear regression (OLS)\n",
    "\n",
    "# Set the model to the variable\n",
    "regressor = LinearRegression()\n",
    "# Fits it to an unscaled dataset\n",
    "regressor.fit(x_train_pol,y_train)\n",
    "results_QC = str(regressor.fit(x_train_pol,y_train))\n",
    "# predict \n",
    "y_pred = regressor.predict(x_test_pol)   \n",
    "# Predicts the x test group based on the fitting of the regressor to the x train and the y train\n",
    "\n",
    "# Here we get the training and test score for the linear regressor model\n",
    "# First we assign them to variables\n",
    "Lin_unscaled_train = (regressor.score(x_train_pol,y_train))\n",
    "Lin_unscaled_test = (regressor.score(x_test_pol,y_test))\n",
    "# Then we print out the outputs\n",
    "print(\"Training set score Linear Regressor: {:.2f}\".format(regressor.score(x_train_pol,y_train)))\n",
    "print(\"Test set score Linear Regressor: {:.2f}\".format(regressor.score(x_test_pol,y_test)))\n",
    "\n",
    "# Prints both actual and predicted as lists - QC Tests so conocked off\n",
    "# print(y_pred)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "#Here the figure size is reset\n",
    "width = 10 \n",
    "height =10\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "# Plot a simple graph to see how well it fits\n",
    "plt.scatter(y_test, y_pred, color ='blue')\n",
    "plt.title('Linear Regression - Actual by Predicted')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "print(\"Results obtained via\",results_QC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we fit a linear regression model again, printing the train and test scores but also looking \n",
    "# at the coefficients of the models\n",
    "\n",
    "lr = LinearRegression().fit(x_train_pol,y_train)\n",
    "lin_coef = lr.coef_\n",
    "# Here we print the coefficients and the intercepts\n",
    "print(\"lr.coef_:\", lr.coef_)\n",
    "print(\"lr.intercept\", lr.intercept_)\n",
    "\n",
    "print(\"Training set score: {:.2f}\".format(lr.score(x_train_pol,y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(x_test_pol,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge with Poly Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Some Feature Engineering for at least 3 different features\n",
    "# here we fit a ridge regression\n",
    "\n",
    "ridge = Ridge().fit(x_train_pol, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train_pol,y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test_pol,y_test)))\n",
    "\n",
    "# Here we do a ridge with an alpha of 10\n",
    "ridge10 = Ridge(alpha=10).fit(x_train_pol, y_train)\n",
    "print(\"Training set ridge 10 score: {:.2f}\".format(ridge10.score(x_train_pol,y_train)))\n",
    "print(\"Test set ridge 10 score: {:.2f}\".format(ridge10.score(x_test_pol,y_test)))\n",
    "\n",
    "training_accuracy_ridge = []\n",
    "test_acc_ridge = []\n",
    "\n",
    "#neighbors_settings = range(0.01)\n",
    "# build the models\n",
    "ridge_a = Ridge(alpha=0.0000001)\n",
    "ridge_a.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_a.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_a.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_b = Ridge(alpha=0.000001)\n",
    "ridge_b.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_b.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_b.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_c = Ridge(alpha=0.00001)\n",
    "ridge_c.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_c.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_c.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_d = Ridge(alpha=0.0001)\n",
    "ridge_d.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_d.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_d.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_e = Ridge(alpha=0.001)\n",
    "ridge_e.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_e.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_e.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_f = Ridge(alpha=0.01)\n",
    "ridge_f.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_f.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_f.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_g = Ridge(alpha=0.1)\n",
    "ridge_g.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_g.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_g.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_h = Ridge(alpha=1.0)\n",
    "ridge_h.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_h.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_h.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_i = Ridge(alpha=10.0)\n",
    "ridge_i.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_i.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_i.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_j = Ridge(alpha=100.0)\n",
    "ridge_j.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_j.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_j.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_k = Ridge(alpha=1000.0)\n",
    "ridge_k.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_k.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_k.score(x_test_pol,y_test))\n",
    "\n",
    "ridge_l = Ridge(alpha=10000.0)\n",
    "ridge_l.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_ridge.append(ridge_l.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_ridge.append(ridge_l.score(x_test_pol,y_test))\n",
    "\n",
    "\n",
    "alpha_settings = (\"1e-7\",\"1e-6\",\"1e-5\",\"1e-4\",\"1e-3\",\"1e-2\",\"1e-1\",\"1\",\"10\",\"100\",\"1000\",\"100000\")\n",
    "plt.plot(alpha_settings,training_accuracy_ridge,label = \"training accuracy\")\n",
    "plt.plot(alpha_settings,test_acc_ridge,label=\"test accuracy\")\n",
    "plt.title('Training vs Test Graph - Ridge Regression - Unscaled')\n",
    "plt.ylabel(\"Accuracy (R^2)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.legend()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we fit the best ridge regressor\n",
    "\n",
    "# Set the model to the variable\n",
    "chosen_ridge = Ridge(alpha=0.01)\n",
    "# Fits it to an unscaled dataset\n",
    "chosen_ridge.fit(x_train_pol,y_train)\n",
    "results_QC = str(chosen_ridge.fit(x_train_pol,y_train))\n",
    "# predict \n",
    "y_pred = chosen_ridge.predict(x_test_pol)   \n",
    "# Predicts the x test group based on the fitting of the regressor to the x train and the y train\n",
    "\n",
    "# Here we get the training and test score for the linear regressor model\n",
    "# First we assign them to variables\n",
    "chosen_ridge_train = (chosen_ridge.score(x_train_pol,y_train))\n",
    "chosen_ridge_test = (chosen_ridge.score(x_test_pol,y_test))\n",
    "# Then we print out the outputs\n",
    "print(\"Training set score chosen ridge: {:.2f}\".format(chosen_ridge.score(x_train_pol,y_train)))\n",
    "print(\"Test set score chosen rdge: {:.2f}\".format(chosen_ridge.score(x_test_pol,y_test)))\n",
    "\n",
    "# Prints both actual and predicted as lists - QC Tests so conocked off\n",
    "# print(y_pred)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "#Here the figure size is reset\n",
    "width = 10 \n",
    "height =10\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "# Plot a simple graph to see how well it fits\n",
    "plt.scatter(y_test, y_pred, color ='blue')\n",
    "plt.title('Chosen_ridge - Actual by Predicted')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "print(\"Results obtained via\",results_QC)\n",
    "\n",
    "#Get the coefficients of the model\n",
    "print(\"coef_:\", chosen_ridge.coef_)\n",
    "# Variable below is used in a graph\n",
    "rid_coef= chosen_ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso with Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a lassoo\n",
    "\n",
    "\n",
    "# Fit a standard lasso with no variation on alpha or iterations\n",
    "lasso = Lasso().fit(x_train_pol,y_train)\n",
    "# prints the train and test scores\n",
    "print(\"Standard untrained Lasso model\")\n",
    "print(\"Training set score {:.2f}\".format(lasso.score(x_train_pol,y_train)))\n",
    "print(\"Tet set score {:.2f}\".format(lasso.score(x_test_pol,y_test)))\n",
    "print(\"number of features used by standard untrined Lasso:\", np.sum(lasso.coef_!=0))\n",
    "print(\"Here we go next\")\n",
    "# In the same manner as previous, create empty arrays to append the lasso regression onto\n",
    "training_accuracy_l = []\n",
    "test_acc_l = []\n",
    "\n",
    "# build the models\n",
    "las_reg_1 = Lasso(alpha=0.0001)\n",
    "las_reg_1.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_1.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_1.score(x_test_pol,y_test))\n",
    "\n",
    "las_reg_2 = Lasso(alpha=0.001)\n",
    "las_reg_2.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_2.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_2.score(x_test_pol,y_test))\n",
    "\n",
    "\n",
    "las_reg_3 = Lasso(alpha=0.01)\n",
    "las_reg_3.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_3.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_3.score(x_test_pol,y_test))\n",
    "\n",
    "las_reg_4 = Lasso(alpha=0.1)\n",
    "las_reg_4.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_4.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_4.score(x_test_pol,y_test))\n",
    "\n",
    "las_reg_5 = Lasso(alpha=1)\n",
    "las_reg_5.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_5.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_5.score(x_test_pol,y_test))\n",
    "\n",
    "las_reg_6 = Lasso(alpha=10)\n",
    "las_reg_6.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_6.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_6.score(x_test_pol,y_test))\n",
    "\n",
    "las_reg_7 = Lasso(alpha=100)\n",
    "las_reg_7.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_7.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_7.score(x_test_pol,y_test))\n",
    "\n",
    "las_reg_8 = Lasso(alpha=1000)\n",
    "las_reg_8.fit(x_train_pol,y_train)\n",
    "# record the accuracy\n",
    "training_accuracy_l.append(las_reg_8.score(x_train_pol,y_train))\n",
    "# record generalization accuracy\n",
    "test_acc_l.append(las_reg_8.score(x_test_pol,y_test))\n",
    "\n",
    "\n",
    "alpha_settings = (\"1e-4\",\"1e-3\",\"1e-2\",\"1e-1\",\"1\",\"10\",\"100\",\"1000\")\n",
    "plt.plot(alpha_settings,training_accuracy_l,label = \"training accuracy\")\n",
    "plt.plot(alpha_settings,test_acc_l,label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy (R^2)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we fit the best Lasso\n",
    "# Set the model to the variable\n",
    "chosen_Lasso = Lasso(alpha=0.01)\n",
    "# Fits it to an unscaled dataset\n",
    "chosen_Lasso.fit(x_train_pol,y_train)\n",
    "results_QC = str(chosen_Lasso.fit(x_train_pol,y_train))\n",
    "# predict \n",
    "y_pred = chosen_Lasso.predict(x_test_pol)   \n",
    "# Predicts the x test group based on the fitting of the regressor to the x train and the y train\n",
    "\n",
    "# Here we get the training and test score for the linear regressor model\n",
    "# First we assign them to variables\n",
    "chosen_Lasso_train = (chosen_Lasso.score(x_train_pol,y_train))\n",
    "chosen_Lasso_test = (chosen_Lasso.score(x_test_pol,y_test))\n",
    "# Then we print out the outputs\n",
    "print(\"Training set score chosen ridge: {:.2f}\".format(chosen_Lasso.score(x_train_pol,y_train)))\n",
    "print(\"Test set score chosen rdge: {:.2f}\".format(chosen_Lasso.score(x_test_pol,y_test)))\n",
    "\n",
    "# Prints both actual and predicted as lists - QC Tests so conocked off\n",
    "# print(y_pred)\n",
    "# print(y_test)\n",
    "\n",
    "#Here the figure size is reset\n",
    "width = 10 \n",
    "height =10\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "# Plot a simple graph to see how well it fits\n",
    "plt.scatter(y_test, y_pred, color ='blue')\n",
    "plt.title('Chosen_Lasso - Actual by Predicted')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "print(\"Results obtained via\",results_QC)\n",
    "\n",
    "#Get the coefficients of the model\n",
    "print(\"coef_:\", chosen_Lasso.coef_)\n",
    "# Variable below is used in a graph\n",
    "Lasso_coef= chosen_Lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with PolyFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_accuracy = []\n",
    "test_acc = []\n",
    "\n",
    "# Here we set the range to between 1 and 15\n",
    "neighbors_settings = range(1,15)\n",
    "\n",
    "# this iterates over all the numbers in the range and appends the training and test scres to each one\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the models\n",
    "    knn_reg_p = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    knn_reg_p.fit(x_train_pol,y_train)\n",
    "    # record the accuracy\n",
    "    training_accuracy.append(knn_reg_p.score(x_train_pol,y_train))\n",
    "    # record generalization accuracy\n",
    "    test_acc.append(knn_reg_p.score(x_test_pol,y_test))\n",
    "\n",
    "\n",
    "# Makes a plot of the training vs test accuracy\n",
    "plt.plot(neighbors_settings,training_accuracy,label = \"training accuracy\")\n",
    "plt.plot(neighbors_settings,test_acc,label=\"test accuracy\")\n",
    "plt.title(\"K Neighbors Regressor\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best actuall by predicted below\n",
    "n_neighbors = 5\n",
    "chosen_knn_reg_p = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "chosen_knn_reg_p.fit(x_train_pol,y_train)\n",
    "y_pred_knn = chosen_knn_reg_p.predict(x_test_pol)\n",
    "#plt.scatter(X_test, y_test, color = 'red')   # Here the train values is set to the test vales\n",
    "plt.scatter(y_test_sc, y_pred_knn, color ='blue')\n",
    "plt.title('Best K Neighbors Regressor Actual vs Predicted, n_neighbors = ')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "# QC Dataset prints\n",
    "#print(y_test_sc)\n",
    "#print(y_pred_svr)\n",
    "# Prints the Training and test accuracy for the selected KNN sets\n",
    "print(\"Training: {:.2f}\".format(chosen_knn_reg_p.score(x_train_pol,y_train)))\n",
    "print(\"Test: {:.2f}\".format(chosen_knn_reg_p.score(x_test_pol,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net with PolyFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The E net needs training from both l1 and alpha reg\n",
    "# Here the inputs are scaled as is most appropriate for this type of model\n",
    "\n",
    "# The L1 is the ratio for the L1 in every model, it will be scaled appropriatley\n",
    "theL1 = 0.8\n",
    "# This method is trained different, it is trained all through alpha, with l1_ratio set - we are ment to re run this scaling \n",
    "# the l1 ratio over and over.\n",
    "\n",
    "# Fit a standard ELlastic Net with no variation on alpha or 1l Reguralization\n",
    "enet_p = ElasticNet().fit(x_train_pol,y_train_sc)\n",
    "# prints the train and test scores\n",
    "print(\"Standard untrained ElasticNet model\")\n",
    "print(\"Training set score {:.2f}\".format(enet_p.score(x_train_pol,y_train_sc)))\n",
    "print(\"Tet set score {:.2f}\".format(enet_p.score(x_test_pol,y_test_sc)))\n",
    "print(\"number of features used by standard untrined Elastic Net:\", np.sum(enet_p.coef_!=0))\n",
    "print(\"Here we go next\")\n",
    "# In the same manner as previous, create empty arrays to append the lasso regression onto\n",
    "training_accuracy_enet_p = []\n",
    "test_acc_enet_p = []\n",
    "\n",
    "# build the models\n",
    "enet_p_reg_1 = ElasticNet(alpha=0.0001,l1_ratio =theL1)\n",
    "enet_p_reg_1.fit(x_train_pol,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet_p.append(enet_p_reg_1.score(x_train_pol,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet_p.append(enet_p_reg_1.score(x_test_pol,y_test_sc))\n",
    "\n",
    "enet_p_reg_2 = ElasticNet(alpha=0.001,l1_ratio =theL1)\n",
    "enet_p_reg_2.fit(x_train_pol,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet_p.append(enet_p_reg_2.score(x_train_pol,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet_p.append(enet_p_reg_2.score(x_test_pol,y_test_sc))\n",
    "\n",
    "enet_p_reg_3 = ElasticNet(alpha=0.01,l1_ratio =theL1)\n",
    "enet_p_reg_3.fit(x_train_pol,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet_p.append(enet_p_reg_3.score(x_train_pol,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet_p.append(enet_p_reg_3.score(x_test_pol,y_test_sc))\n",
    "\n",
    "enet_p_reg_4 = ElasticNet(alpha=0.1,l1_ratio =theL1)\n",
    "enet_p_reg_4.fit(x_train_pol,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet_p.append(enet_p_reg_4.score(x_train_pol,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet_p.append(enet_p_reg_4.score(x_test_pol,y_test_sc))\n",
    "\n",
    "enet_p_reg_5 = ElasticNet(alpha=1,l1_ratio =theL1)\n",
    "enet_p_reg_5.fit(x_train_pol,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet_p.append(enet_p_reg_5.score(x_train_pol,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet_p.append(enet_p_reg_5.score(x_test_pol,y_test_sc))\n",
    "\n",
    "enet_p_reg_6 = ElasticNet(alpha=10,l1_ratio =theL1)\n",
    "enet_p_reg_6.fit(x_train_pol,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet_p.append(enet_p_reg_6.score(x_train_pol,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet_p.append(enet_p_reg_6.score(x_test_pol,y_test_sc))\n",
    "\n",
    "enet_p_reg_7 = ElasticNet(alpha=100,l1_ratio =theL1)\n",
    "enet_p_reg_7.fit(x_train_pol,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet_p.append(enet_p_reg_7.score(x_train_pol,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet_p.append(enet_p_reg_7.score(x_test_pol,y_test_sc))\n",
    "\n",
    "enet_p_reg_8 = ElasticNet(alpha=1000,l1_ratio =theL1)\n",
    "enet_p_reg_8.fit(x_train_pol,y_train_sc)\n",
    "# record the accuracy\n",
    "training_accuracy_enet_p.append(enet_p_reg_8.score(x_train_pol,y_train_sc))\n",
    "# record generalization accuracy\n",
    "test_acc_enet_p.append(enet_p_reg_8.score(x_test_pol,y_test_sc))\n",
    "\n",
    "\n",
    "alpha_settings = (\"1e-4\",\"1e-3\",\"1e-2\",\"1e-1\",\"1\",\"10\",\"100\",\"1000\")\n",
    "plt.plot(alpha_settings,training_accuracy_enet_p,label = \"training accuracy\")\n",
    "plt.plot(alpha_settings,test_acc_enet_p,label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy (R^2)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best actuall by predicted below\n",
    "# Here are the best parameters as a variable\n",
    "alpha = 10\n",
    "l1_ratio = 0.8\n",
    "\n",
    "chosen_enet_p = ElasticNet(alpha = alpha,l1_ratio =l1_ratio)\n",
    "chosen_enet_p.fit(x_train_pol,y_train)\n",
    "y_pred_enet = chosen_enet_p.predict(x_test_pol)\n",
    "#plt.scatter(X_test, y_test, color = 'red')   # Here the train values is set to the test vales\n",
    "plt.scatter(y_test_sc, y_pred_enet, color ='blue')\n",
    "plt.title('Best Elastic Net Regressor Actual vs Predicted, alpha =, l1 = ')\n",
    "plt.xlabel('Actuall')\n",
    "plt.ylabel('Predicted')\n",
    "# QC Dataset prints\n",
    "#print(y_test_sc)\n",
    "#print(y_pred_svr)\n",
    "# Prints the Training and test accuracy for the model\n",
    "print(\"Training: {:.2f}\".format(chosen_enet_p.score(x_train_pol,y_train)))\n",
    "print(\"Test: {:.2f}\".format(chosen_enet_p.score(x_test_pol,y_test)))\n",
    "\n",
    "#Get the coefficients of the model\n",
    "print(\"coef_:\", chosen_enet_p.coef_)\n",
    "# Variable below is used in a graph\n",
    "enet_coef_p= chosen_enet_p.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we fit the coefficient graph for all the best models\n",
    "\n",
    "# Need to alter the x axis names\n",
    "x_ax = (\"x1\",\"x2\",\"x3\",\"x4\",\"x5\",\"x6\",\"x7\",\"x8\")\n",
    "\n",
    "\n",
    "lin_coef=np.array(lin_coef)\n",
    "lin_coef=lin_coef.flatten()\n",
    "\n",
    "rid_coef=np.array(rid_coef)\n",
    "rid_coef=rid_coef.flatten()\n",
    "\n",
    "Lasso_coef = np.array(Lasso_coef)\n",
    "Lasso_coef = Lasso_coef.flatten()\n",
    "\n",
    "# There is no coef call for a KNN model\n",
    "\n",
    "#enet_coef = np.array(enet_coef)\n",
    "#enet_coef = enet_coef.flatten()\n",
    "\n",
    "#lin_coef = list(lin_coef)\n",
    "plt.xticks(rotation=90)\n",
    "plt.plot(feat_name_poly,lin_coef,label = \"Linear Coef\")\n",
    "plt.plot(rid_coef,label=\"Ridge Coef\")\n",
    "plt.plot(Lasso_coef,label=\"Lasso Coef\")\n",
    "plt.plot(enet_coef_p,label=\"Elastic Net Coef\")\n",
    "plt.ylabel(\"Coefficient Power\")\n",
    "plt.xlabel(\"Factor\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
